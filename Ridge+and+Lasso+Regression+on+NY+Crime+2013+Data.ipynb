{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Building a maultivariable regressor using crime data in New York State in 2013(Source: FBI, UCR.)\n",
    "We try to predict occurrence of murder in any city using other crime related data</h2>\n",
    "\n",
    "To reduce the risk of overfitting we will apply following regularization procedures for the linear regression:\n",
    "\n",
    "- Ridge Regression: where Ordinary Least Squares is modified to also minimize the squared absolute sum of the coefficients (called L2 regularization).\n",
    "- Lasso Regression: where Ordinary Least Squares is modified to also minimize the absolute sum of the coefficients (called L1 regularization).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab and process the cleaned data\n",
    "path1 = (\"C:/Users/aath/Dropbox/MAEN/Thankful/Data/NY Crime/NY_Crime_2013_cleaned2.csv\")\n",
    "\n",
    "df = pd.read_csv(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>prop</th>\n",
       "      <th>pop</th>\n",
       "      <th>murd</th>\n",
       "      <th>rob</th>\n",
       "      <th>violent</th>\n",
       "      <th>assul</th>\n",
       "      <th>burg</th>\n",
       "      <th>theft</th>\n",
       "      <th>motor</th>\n",
       "      <th>murd_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adams Village</td>\n",
       "      <td>11</td>\n",
       "      <td>1851</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Addison Town and Village</td>\n",
       "      <td>49</td>\n",
       "      <td>2568</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afton Village4</td>\n",
       "      <td>1</td>\n",
       "      <td>820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akron Village</td>\n",
       "      <td>17</td>\n",
       "      <td>2842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albany4</td>\n",
       "      <td>3888</td>\n",
       "      <td>98595</td>\n",
       "      <td>8</td>\n",
       "      <td>237</td>\n",
       "      <td>802</td>\n",
       "      <td>503</td>\n",
       "      <td>683</td>\n",
       "      <td>3083</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       City  prop    pop  murd  rob  violent  assul  burg  \\\n",
       "0             Adams Village    11   1851     0    0        0      0     1   \n",
       "1  Addison Town and Village    49   2568     0    1        2      1     1   \n",
       "2            Afton Village4     1    820     0    0        0      0     0   \n",
       "3             Akron Village    17   2842     0    0        1      1     0   \n",
       "4                   Albany4  3888  98595     8  237      802    503   683   \n",
       "\n",
       "   theft  motor  murd_binary  \n",
       "0     10      0            0  \n",
       "1     47      1            0  \n",
       "2      1      0            0  \n",
       "3     17      0            0  \n",
       "4   3083    122            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Remove New York City as it is the largest city in NY State and does distort visualization\n",
    "df = df[df.City != 'New York']\n",
    "\n",
    "# Murder = murd is our dependent binary variable already represented by murd_binayr. \n",
    "# City is not \n",
    "df = df.drop('murd',1)\n",
    "df = df.drop('City',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prop           0\n",
       "pop            0\n",
       "rob            0\n",
       "violent        0\n",
       "assul          0\n",
       "burg           0\n",
       "theft          0\n",
       "motor          0\n",
       "murd_binary    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "trainsize = int(df.shape[0] / 2)\n",
    "chosen_idx1 = np.random.choice(df.shape[0], replace=False, size=trainsize)\n",
    "chosen_idx2 = np.random.choice(df.shape[0], replace=False, size=trainsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-88b2c9c93264>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchosen_idx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchosen_idx1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mchosen_idx1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchosen_idx1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "chosen_idx2 = chosen_idx1[~chosen_idx1.index.isin(chosen_idx1.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training and test sizes.\n",
    "df.sample(frac=1) # Shuffle the data\n",
    "trainsize = int(df.shape[0] / 2)\n",
    "df_test = df.iloc[trainsize:, :].copy()\n",
    "df_train = df.iloc[:trainsize, :].copy()\n",
    "\n",
    "# Set up the regression model to predict defaults using all other\n",
    "# variables as features.\n",
    "regr1 = linear_model.LinearRegression()\n",
    "Y_train = df_train['murd_binary'].values.reshape(-1, 1)\n",
    "X_train = df_train.loc[:, ~(df_train.columns).isin(['murd_binary'])]\n",
    "regr1.fit(X_train, Y_train)\n",
    "print('\\nR-squared simple model:')\n",
    "print(regr1.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This model explains 37% of variability of the response data around the mean.\n",
    "- R-squared = Explained variation / Total variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the parameter estimates.\n",
    "origparams = np.append(regr1.coef_, regr1.intercept_)\n",
    "origparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make new features to capture potential quadratic\n",
    "# between the features.\n",
    "\n",
    "df_train['prop2'] = (df_train['prop'] + 100) ** 2\n",
    "df_train['pop2'] = (df_train['pop'] + 100) ** 2\n",
    "df_train['rob2'] = (df_train['rob'] + 100) ** 2\n",
    "df_train['violent2'] = (df_train['violent'] + 100) ** 2\n",
    "df_train['assul2'] = (df_train['assul'] + 100) ** 2\n",
    "df_train['burg2'] = (df_train['burg'] + 100) ** 2\n",
    "df_train['theft2'] = (df_train['theft'] + 100) ** 2\n",
    "df_train['mortor2'] = (df_train['motor'] + 100) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the model with the new features.\n",
    "regrBig = linear_model.LinearRegression()\n",
    "X_train2 = df_train.loc[:, ~(df_train.columns).isin(['murd_binary'])]\n",
    "regrBig.fit(X_train2, Y_train)\n",
    "print('\\nR-squared complex model:')\n",
    "print(regrBig.score(X_train2, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- R-squared increases by added features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the new parameter estimates for the same features.\n",
    "newparams = np.append(\n",
    "    regrBig.coef_[0,0:(len(origparams)-1)],\n",
    "    regrBig.intercept_)\n",
    "\n",
    "print('\\nParameter Estimates for the same predictors for the small model '\n",
    "      'and large model:')\n",
    "compare = np.column_stack((origparams, newparams))\n",
    "prettycompare = np.array2string(\n",
    "    compare,\n",
    "    formatter={'float_kind':'{0:.3f}'.format})\n",
    "print(prettycompare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After adding extra features, the magnitute and sign of some of coefficients changed. This can be a sign of overfitting and of having too many correlated dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the simpler model with smaller coefficients.\n",
    "Y_test = df_test['murd_binary'].values.reshape(-1, 1)\n",
    "X_test = df_test.loc[:, ~(df_test.columns).isin(['murd_binary'])]\n",
    "print('\\nR-squared simple model:')\n",
    "print(regr1.score(X_test, Y_test))\n",
    "\n",
    "# Test the more complex model with larger coefficients.\n",
    "\n",
    "df_test['prop2'] = (df_test['prop'] + 100) ** 2\n",
    "df_test['pop2'] = (df_test['pop'] + 100) ** 2\n",
    "df_test['rob2'] = (df_test['rob'] + 100) ** 2\n",
    "df_test['violent2'] = (df_test['violent'] + 100) ** 2\n",
    "df_test['assul2'] = (df_test['assul'] + 100) ** 2\n",
    "df_test['burg2'] = (df_test['burg'] + 100) ** 2\n",
    "df_test['theft2'] = (df_test['theft'] + 100) ** 2\n",
    "df_test['mortor2'] = (df_test['motor'] + 100) ** 2\n",
    "\n",
    "# Re-run the model with the new features.\n",
    "X_test2 = df_test.loc[:, ~(df_test.columns).isin(['murd_binary'])]\n",
    "print('\\nR-squared complex model:')\n",
    "print(regrBig.score(X_test2, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Testing the model on remaining data set result in a very poor outcome. A negative R-squared indicates that the fit of the model is even worse than a horizontal line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, we try to improve the model by using Ridge procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To address the overfitting problem we can neglect the requirement of an unbiased parameter estimator \n",
    "# and instead use a biased estimator, which may have smaller variance.\n",
    "# One of such biased estimators is the Ridge method. \n",
    "# Below we will fit a ridge regression model where alpha is the regularization parameter (usually called lambda). \n",
    "# As alpha gets larger, parameter shrinkage grows more pronounced. Note that by convention, the intercept is not regularized. \n",
    "\n",
    "ridgeregr = linear_model.Ridge(alpha=20, fit_intercept=False) \n",
    "ridgeregr.fit(X_train, Y_train)\n",
    "print(ridgeregr.score(X_train, Y_train))\n",
    "origparams = ridgeregr.coef_[0]\n",
    "print(origparams)\n",
    "\n",
    "ridgeregrBig = linear_model.Ridge(alpha=20, fit_intercept=False)\n",
    "ridgeregrBig.fit(X_train2, Y_train)\n",
    "print(ridgeregrBig.score(X_train2, Y_train))\n",
    "newparams = ridgeregrBig.coef_[0, 0:len(origparams)]\n",
    "\n",
    "print('\\nParameter Estimates for the same predictors for the small model'\n",
    "      ' and large model:')\n",
    "compare = np.column_stack((origparams, newparams))\n",
    "prettycompare = np.array2string(\n",
    "    compare,\n",
    "    formatter={'float_kind':'{0:.3f}'.format})\n",
    "print(prettycompare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nR-squared simple model:')\n",
    "print(ridgeregr.score(X_test, Y_test))\n",
    "print('\\nR-squared complex model:')\n",
    "print(ridgeregrBig.score(X_test2, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Risdge regression using regularization parameter λ = 20 make the model worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, we try to improve the model by using Lasso procedure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following we will use Lasso Regression which is a close cousin of Ridge Regression, in which absolute values of coefficients are minimized rather than the square of values. This method will help to eliminate some insignificant variables. Lasso regression is generally used when there is a very large number of variables, since Lasso automatically does the variables selection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small number of parameters.\n",
    "lass = linear_model.Lasso(alpha=.35)\n",
    "lassfit = lass.fit(X_train, Y_train)\n",
    "print('R² for the model with few features:')\n",
    "print(lass.score(X_train, Y_train))\n",
    "origparams = np.append(lassfit.coef_, lassfit.intercept_)\n",
    "print('\\nParameter estimates for the model with few features:')\n",
    "print(origparams)\n",
    "\n",
    "# Large number of parameters.\n",
    "lassBig = linear_model.Lasso(alpha=.35)\n",
    "lassBig.fit(X_train2, Y_train)\n",
    "print('\\nR² for the model with many features:')\n",
    "print(lassBig.score(X_train2, Y_train))\n",
    "origparams = np.append(lassBig.coef_, lassBig.intercept_)\n",
    "print('\\nParameter estimates for the model with many features:')\n",
    "print(origparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking predictive power using the test set:\n",
    "print('\\nR-squared simple model:')\n",
    "print(lass.score(X_test, Y_test))\n",
    "print('\\nR-squared complex model:')\n",
    "print(lassBig.score(X_test2, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the Lasso method the model improves considerably compared to previous models. However, because of negative R-squared we can conclude that this model, with its constraints, fits the data really poorly.\n",
    "- We can also see that the Lasso method is able to make a selection of variables. Overall we can say that both Lasso and Ridge balance the trade-off bias-variance with the choice of lambda. On this dataset the Lasso performed better and apparently it was because of many of predators were not actually tied to the response variable. And to test this one should use cross-validation and also try to do an stepwise regression. Here we started with all variables and tried to reduce or shrink them. Another approach is to go forward stepwise by starting with an empty model and choose the variables with most significant association. In each step we add variable that can provide statistically significant association with the dependent variable. By using cross-validation and pipeline module we should be able to find and select the best variables in a backward and forward stepwise fashon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
